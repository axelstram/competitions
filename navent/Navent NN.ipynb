{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn import metrics\n",
    "from collections import OrderedDict, defaultdict\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.merge import concatenate, dot, multiply, add\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "from keras import losses\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from hyperopt import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import PurePath\n",
    "\n",
    "from fastai.structured import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica de evaluación\n",
    "def RMSLE(actual, pred):\n",
    "    return (np.mean((np.log(actual + 1) - np.log(pred + 1)) ** 2)) **.5\n",
    "\n",
    "def RMSE(actual, pred):\n",
    "    return (np.mean((actual - pred) ** 2)) **.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_fit(col, df_train, df_test):\n",
    "    tokenizer = Tokenizer(filters='', lower=True)\n",
    "    tokenizer.fit_on_texts(df_train[col])\n",
    "    train_sequences = np.array(tokenizer.texts_to_sequences(df_train[col]))\n",
    "    test_sequences = np.array(tokenizer.texts_to_sequences(df_test[col]))\n",
    "    \n",
    "    return train_sequences, test_sequences, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_nn():\n",
    "    K.clear_session()\n",
    "    inp_region = Input(shape=(1, ), name='inp_region')\n",
    "    emb_region = Embedding(len_region, size_emb_region, name='emb_region')(inp_region)\n",
    "    emb_region = Reshape(target_shape=(size_emb_region,))(emb_region)\n",
    "    \n",
    "    inp_parentcatname = Input(shape=(1, ), name='inp_parent_category_name')\n",
    "    emb_parentcatname = Embedding(len_parentcatname, size_emb_parentcatname, name='emb_parent_category_name')(inp_parentcatname)\n",
    "    emb_parentcatname = Reshape(target_shape=(size_emb_parentcatname,))(emb_parentcatname)\n",
    "    \n",
    "    inp_catname = Input(shape=(1, ), name='inp_category_name')\n",
    "    emb_catname = Embedding(len_catname, size_emb_catname, name=\"emb_category_name\")(inp_catname)\n",
    "    emb_catname = Reshape(target_shape=(size_emb_catname,))(emb_catname)\n",
    "    \n",
    "    inp_usertype = Input(shape=(1, ), name='inp_user_type')\n",
    "    emb_usertype = Embedding(len_usertype, size_emb_usertype, name='emb_user_type')(inp_usertype)\n",
    "    emb_usertype = Reshape(target_shape=(size_emb_usertype,))(emb_usertype)\n",
    "        \n",
    "    inp_city = Input(shape=(1, ), name='inp_city')\n",
    "    emb_city = Embedding(len_city, size_emb_city, name='emb_city')(inp_city)\n",
    "    emb_city = Reshape(target_shape=(size_emb_city,))(emb_city)\n",
    "    \n",
    "    inp_week = Input(shape=(1, ), name='inp_week')\n",
    "    emb_week = Embedding(len_week, size_emb_week, name='emb_week')(inp_week)\n",
    "    emb_week = Reshape(target_shape=(size_emb_week,))(emb_week)\n",
    "    \n",
    "    inp_day = Input(shape=(1, ), name='inp_day_of_month')\n",
    "    emb_day = Embedding(len_day_month, size_emb_day_month, name='emb_day_of_month')(inp_day)\n",
    "    emb_day = Reshape(target_shape=(size_emb_day_month,))(emb_day)\n",
    "    \n",
    "    inp_imgt1 = Input(shape=(1, ), name='inp_imgt1')\n",
    "    emb_imgt1 = Embedding(len_imgt1, size_emb_imgt1, name='emb_imgt1')(inp_imgt1)\n",
    "    emb_imgt1 = Reshape(target_shape=(size_emb_imgt1,))(emb_imgt1)\n",
    "    \n",
    "    inp_price = Input(shape=(1, ), name='inp_price')\n",
    "    #x = GaussianNoise(1)(inp_price)\n",
    "    #emb_price = Dense(size_emb_price, activation='tanh', name='emb_price')(x)\n",
    "\n",
    "    inp_itemseq = Input(shape=(1, ), name='inp_itemseq')\n",
    "    #emb_itemseq = Dense(size_emb_itemseq, activation='tanh', name='emb_itemseq')(inp_itemseq)\n",
    "    \n",
    "    #inp_feat_eng = Input(shape=(len_feat_eng, ), name='inp_feat_eng')\n",
    "    #x = GaussianNoise(1)(inp_feat_eng)\n",
    "    #emb_feat_eng = Dense(size_emb_feat_eng, activation='tanh', name='emb_feat_eng')(x)\n",
    "    \n",
    "    conc_cat_and_cont = concatenate([emb_region, emb_parentcatname, emb_catname, emb_usertype, emb_city, emb_week, \n",
    "                             emb_day, emb_imgt1, inp_price, inp_itemseq], axis=-1, name='concat_cat_and_cont')\n",
    "    \n",
    "#     x = Dropout(dropout)(conc_cat_and_cont)\n",
    "#     x = Dense(25, activation='relu')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Dropout(dropout)(x)\n",
    "#     conc_cat_and_cont = Dense(25, activation='relu')(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    ### title\n",
    "    # channel 1\n",
    "   \n",
    "    embedding = Embedding(vocabulary_size, size_emb_title, name='emb_title_1')\n",
    "    \n",
    "#     input_title_1 = Input(shape=(maxlen_title,), name='input_title_1')\n",
    "#     embedding_for_title = embedding(input_title_1)\n",
    "#     x = Dropout(dropout)(embedding_for_title)\n",
    "#     x = GRU(5, dropout=dropout, recurrent_dropout=dropout, return_sequences=True)(x)\n",
    "#     title_layer = GRU(5, dropout=dropout, recurrent_dropout=dropout, return_sequences=False)(x)\n",
    "    \n",
    "    \n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Dropout(dropout)(x)\n",
    "    #x = Conv1D(filters=8, kernel_size=1, activation='relu')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Dropout(dropout)(x)\n",
    "    #x = Conv1D(filters=8, kernel_size=1, activation='relu')(x)\n",
    "    #avg_pool = GlobalAveragePooling1D()(x)\n",
    "    #max_pool = GlobalMaxPooling1D()(x)\n",
    "    #title_layer = concatenate([avg_pool, max_pool])\n",
    "    \n",
    "    input_descr_1 = Input(shape=(maxlen_description, ), name='inp_descr_1')\n",
    "    embedding_for_descr = embedding(input_descr_1)\n",
    "    #x = Dropout(dropout)(embedding_for_descr)\n",
    "    descr_layer = GRU(50)(embedding_for_descr)\n",
    "    # = GRU(5, dropout=dropout, recurrent_dropout=dropout, return_sequences=False)(x)\n",
    "    \n",
    "\n",
    "    conc_all = concatenate([conc_cat_and_cont, descr_layer], axis=-1)\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    #x = Dropout(dropout)(conc_all)\n",
    "    x = Dense(500, activation='relu')(conc_all)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    y = Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "    model = Model(inputs = [inp_region, inp_parentcatname, inp_catname, inp_usertype, inp_city, inp_week, inp_day, inp_imgt1, inp_price, inp_itemseq,\n",
    "                            input_descr_1, #input_descr_2, input_descr_3,\n",
    "                            #inp_descr,\n",
    "                            #input_title_1, #input_title_2, input_title_3,\n",
    "                            #input_params_1,# input_params_2, input_params_3,\n",
    "                            #input_img\n",
    "                           ], outputs = y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', index_col='id', parse_dates=['fecha'])\n",
    "df_test = pd.read_csv('test.csv', parse_dates=['fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = [\"titulo\", \"descripcion\", \"direccion\"]\n",
    "\n",
    "for col in text_features:\n",
    "    df[col].fillna('', inplace=True)\n",
    "    df[col] = df[col].str.lower()\n",
    "    df_test[col].fillna('', inplace=True)\n",
    "    df_test[col] = df_test[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['año'] = df.fecha.dt.year\n",
    "df['mes'] = df.fecha.dt.month\n",
    "\n",
    "df_test['año'] = df_test.fecha.dt.year\n",
    "df_test['mes'] = df_test.fecha.dt.month\n",
    "\n",
    "df.drop(['fecha'], axis=1, inplace=True)\n",
    "df_test.drop(['fecha'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ciudad'] = df['ciudad'].str.lower()\n",
    "df['provincia'] = df['provincia'].str.lower()\n",
    "\n",
    "df_test['ciudad'] = df_test['ciudad'].str.lower()\n",
    "df_test['provincia'] = df_test['provincia'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df_all = pd.concat([df, df_test], axis=0)\n",
    "# # Iterate through the columns\n",
    "for col in df_all:\n",
    "    if col == 'titulo' or col == 'descripcion' or col == 'direccion':\n",
    "        continue\n",
    "        \n",
    "    if df_all[col].dtype == 'object':\n",
    "        le.fit(df_all[col].astype(str))\n",
    "        # Transform both training and testing data\n",
    "        df[col] = le.transform(df[col].astype(str))\n",
    "        df_test[col] = le.transform(df_test[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size, lower='True')\n",
    "tokenizer.fit_on_texts(np.append(df['titulo'].values, [df['descripcion'].values, df['direccion'].values]))\n",
    "\n",
    "\n",
    "title_train = tokenizer.texts_to_sequences(df['titulo'].values)\n",
    "title_test = tokenizer.texts_to_sequences(df_test['titulo'].values)\n",
    "\n",
    "descr_train = tokenizer.texts_to_sequences(df['descripcion'].values)\n",
    "descr_test = tokenizer.texts_to_sequences(df_test['descripcion'].values)\n",
    "\n",
    "dir_train = tokenizer.texts_to_sequences(df['direccion'].values)\n",
    "dir_test = tokenizer.texts_to_sequences(df_test['direccion'].values)\n",
    "\n",
    "maxlen_title = 30\n",
    "title_train_pad = pad_sequences(title_train, maxlen=maxlen_title)\n",
    "title_test_pad = pad_sequences(title_test, maxlen=maxlen_title)\n",
    "\n",
    "maxlen_description = 50\n",
    "descr_train_pad = pad_sequences(descr_train, maxlen=maxlen_description)\n",
    "descr_test_pad = pad_sequences(descr_test, maxlen=maxlen_description)\n",
    "\n",
    "maxlen_params = 30\n",
    "dir_train_pad = pad_sequences(dir_train, maxlen=maxlen_params)\n",
    "dir_test_pad = pad_sequences(dir_test, maxlen=maxlen_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tipodepropiedad, test_tipodepropiedad, tokenizer_tipodepropiedad = tokenizer_fit('tipodepropiedad', df, df_test)\n",
    "train_idzona, test_idzona, tokenizer_idzona = tokenizer_fit('idzona', df, df_test)\n",
    "train_ciudad, test_ciudad, tokenizer_ciudad = tokenizer_fit('ciudad', df, df_test)\n",
    "train_provincia, test_provincia, tokenizer_provincia = tokenizer_fit('provincia', df, df_test)\n",
    "train_año, test_año, tokenizer_año = tokenizer_fit('año', df, df_test)\n",
    "train_mes, test_mes, tokenizer_mes = tokenizer_fit('mes', df, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## categorical\n",
    "size_emb_tipodepropiedad = 25\n",
    "size_emb_idzona = 19719\n",
    "size_emb_ciudad = 876\n",
    "size_emb_provincia = 33\n",
    "\n",
    "size_emb_año = 5\n",
    "size_emb_mes = 12\n",
    "\n",
    "size_emb_antiguedad = 1\n",
    "size_emb_habitaciones = 1\n",
    "\n",
    "size_emb_garages = 2\n",
    "size_emb_banos = 2\n",
    "size_emb_gimnasio = 2\n",
    "size_emb_usosmultiples = 2\n",
    "size_emb_piscina = 2\n",
    "size_emb_escuelascercanas = 2\n",
    "size_emb_centroscomercialescercanos = 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
